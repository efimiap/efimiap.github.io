---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a final year DPhil (PhD) student at [MRG](https://ori.ox.ac.uk/labs/mobile-robotics-group/) and [CRG](https://ori.ox.ac.uk/labs/cognitive-robotics-group/) at the [Oxford Robotics Institute](https://ori.ox.ac.uk/), University of Oxford, supervised by [Daniele De Martini](https://scholar.google.com/citations?user=F7QcGh0AAAAJ&hl=en), [Paul Newman](https://scholar.google.com/citations?user=BtO5fTUAAAAJ&hl=en), and [Lars Kunze](https://scholar.google.co.uk/citations?user=TLC0azYAAAAJ&hl=en). For my studies, I have been awarded the Oxford - Google DeepMind research scholarship. 

Currently, I am also working part-time at [OXA](https://oxa.tech/) as Senior ML Engineer, at the Office of the CTO. Before starting my DPhil, I was working as Lead Self-Driving Software Engineer at [StreetDrone](https://www.streetdrone.com/) (acquired by OXA) and worked as Data Engineer at [Williams Racing Formula 1](https://www.williamsf1.com/).

I finished my MEng in 2017 at [NTUA](https://www.ntua.gr/en/), Greece, Department of [Electrical and Computer Engineering](https://www.ece.ntua.gr/en). During my studies, I spent time at [ETH Z√ºrich](https://ethz.ch/en.html) conducting my master's thesis at the [Computer Vision Lab](https://vision.ee.ethz.ch/) under the supervision of [Prof Luc Van Gool](https://scholar.google.co.uk/citations?user=TwMib_QAAAAJ&hl=en) and [Dr Dengxin Dai](https://scholar.google.co.uk/citations?user=T51W57YAAAAJ&hl=en), working with [AMZ Driverless](https://www.amzracing.ch/en).


My research focuses on introspective robot learning and neurosymbolic AI, with work on graph learning, scene understanding, neural algorithmic reasoning, semantic localisation, and explainability.

## Latest Research

<div class="research-section">
  
  <!-- Project 1 -->
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/nar.jpg" alt="Project 1" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
      <h3>NAR-* ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms</h3>
      <p>Efimia Panagiotaki, Daniele De Martini, Lars Kunze, Paul Newman, and Petar Veliƒçkoviƒá</p>
      <p>Neural algorithmic reasoning for point cloud registration, emulating the reasoning steps of classical algorithms.</p>
      <div class="project-links">
        <a href="https://arxiv.org/abs/2410.11031" class="btn btn--primary">üìÑ Paper</a>
      </div>
    </div>
  </div>

<!-- Project 2 -->
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/gnarly.png" alt="Project 2" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
      <h3>Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning</h3>
      <p>Alex Schutz, Victor-Alexandru Darvariu, Efimia Panagiotaki, Bruno Lacerda, and Nick Hawes</p>
      <p>A framework that frames algorithmic trajectory learning as an MDP and applies imitation learning and RL to solve combinatorial NP-hard problems.</p>
      <div class="project-links">
        <a href="https://arxiv.org/abs/2509.18930" class="btn btn--primary">üìÑ Paper</a>
      </div>
    </div>
  </div>

  <!-- Project 3 -->
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/graphscene/graphscene_combo.png" alt="Project 3" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
      <h3>GraphSCENE: On-Demand Critical Scenario Generation for Autonomous Vehicles in Simulation
      <div style="display: inline-block; background-color: #aad2ffff; color: black; padding: 4px 8px; font-size: 0.7em; margin: 5px 0; font-weight: bold;">IROS'25</div></h3>
      <p>Efimia Panagiotaki, Georgi Pramatarov, Lars Kunze, and Daniele De Martini</p>
      <p>A temporal GNN-based method to automatically generate diverse, safety-critical traffic scenarios in simulation on-demand, grounded on real-world datasets.</p>
      <div class="project-links">
        <a href="https://arxiv.org/abs/2410.13514" class="btn btn--primary">üìÑ Paper</a>
        <a href="https://efimiap.github.io/graphscene/" class="btn btn--info">üåê Website</a>
      </div>
    </div>
  </div>

  <!-- Project 4 -->
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/rc.png" alt="Project 4" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
      <h3>The Oxford RobotCycle Project: A Multimodal Urban Cycling Dataset for Assessing the Safety of Vulnerable Road Users
      <div style="display: inline-block; background-color: #aad2ffff; color: black; padding: 4px 8px; font-size: 0.7em; margin: 5px 0; font-weight: bold;">T-FR'25</div></h3>
      <p>Efimia Panagiotaki, Divya Thuremella, Jumana Baghabrah, Samuel Sze, Lanke Frank Tarimo Fu, Benjamin Hardin, Tyler Reinmund, Tobit Flatscher, Daniel Marques, Chris Prahacs, Lars Kunze, and Daniele De Martini</p>
      <p>Large-scale multimodal dataset, including eye-gaze data, capturing first-person ego-cyclist perspective.</p>
      <div class="project-links">
        <a href="https://ieeexplore.ieee.org/abstract/document/10981746/" class="btn btn--primary">üìÑ Paper</a>
        <a href="https://ori-mrg.github.io/robotcycle-dataset/" class="btn btn--info">üåê Website</a>
      </div>
    </div>
  </div>

  <!-- Project 5 -->
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/oord.png" alt="Project 5" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
      <h3>OORD: The Oxford Offroad Radar Dataset
      <div style="display: inline-block; background-color: #aad2ffff; color: black; padding: 4px 8px; font-size: 0.7em; margin: 5px 0; font-weight: bold;">T-ITS'24</div></h3>
      <p>Matthew Gadd, Daniele De Martini, Oliver Bartlett, Paul Murcutt, Matt Towlson, Matthew Widojo, Valentina Mu≈üat, Luke Robinson, Efimia Panagiotaki, Georgi Pramatarov, Marc Alexander K√ºhn, Letizia Marchegiani, Paul Newman, and Lars Kunze.</p>
      <p>Radar and GPS/INS Dataset collected in the rugged Scottish highlands in extreme weather</p>
      <div class="project-links">
        <a href="https://ieeexplore.ieee.org/abstract/document/10648882" class="btn btn--primary">üìÑ Paper</a>
        <a href="https://oxford-robotics-institute.github.io/oord-dataset/" class="btn btn--info">üåê Website</a>
      </div>
    </div>
  </div>


  <!-- Project 6
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/semgat.png" alt="Project 6" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
      <h3>Sem-gat: Explainable semantic pose estimation using learned graph attention
      <div style="display: inline-block; background-color: #aad2ffff; color: black; padding: 4px 8px; font-size: 0.7em; margin: 5px 0; font-weight: bold;">ICAR'23</div></h3>
      <p>Efimia Panagiotaki, Daniele De Martini, Georgi Pramatarov, Matthew Gadd, and Lars Kunze</p>
      <p>A lightweight GNN-based method that leverages semantic and geometric cues with cross-graph attention to enable efficient, accurate, and introspective point cloud registration.</p>
      <div class="project-links">
        <a href="https://ieeexplore.ieee.org/abstract/document/10407013" class="btn btn--primary">üìÑ Paper</a>
      </div>
    </div>
  </div> -->

  <!-- Project 7
  <div class="research-project">
    <div class="project-image">
      <img src="{{ base_path }}/images/explainability.png" alt="Project 7" style="width: 200px; height: 150px; object-fit: contain;">
    </div>
    <div class="project-content">
            <h3>Semantic interpretation and validation of graph attention-based explanations for GNN models
      <div style="display: inline-block; background-color: #aad2ffff; color: black; padding: 4px 8px; font-size: 0.7em; margin: 5px 0; font-weight: bold;">ICAR'23</div></h3>
      <p>Efimia Panagiotaki, Daniele De Martini, and Lars Kunze</p>
      <p>A methodology for evaluating the accuracy of using attention weights as feature importance indicators.</p>
      <div class="project-links">
        <a href="https://ieeexplore.ieee.org/abstract/document/10407013" class="btn btn--primary">üìÑ Paper</a>
      </div>
    </div>
  </div> -->

  <!-- View All Button -->
  <div style="text-align: right; margin-top: 30px;">
    <a href="{{ base_path }}/publications/" class="btn btn--primary" style="padding: 6px 10px; font-size: 0.8em;"> All Publications ‚û°Ô∏è</a>
  </div>

</div>




